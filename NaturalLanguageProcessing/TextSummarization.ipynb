{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mobicfd/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/mobicfd/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f = open(\"./10.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fread = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xe2\\x80\\x9cWith a surface temperature of 10,000 degrees Fahrenheit and frequent eruptions of ionized gases flowing along strong magnetic fields, the sun is the first star we\\xe2\\x80\\x99ve seen with the right conditions to support fire organisms, and we believe there is evidence to support the theory that fire-bacteria, fire-insects, and even tiny fire-fish were once perhaps populous on the sun\\xe2\\x80\\x99s surface.\\xe2\\x80\\x9d Scientists cautioned that despite the exciting possibilities of fire-life on the star, there are numerous logistical, moral, and ethical questions to resolve before scientists could even begin to entertain the possibility of putting fire-people on the sun. \\xef\\xbb\\xbfWASHINGTON In an announcement'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fread=fread.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Tokenize the text using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_tokens = nltk.word_tokenize(fread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\\u201cWith',\n",
       " u'a',\n",
       " u'surface',\n",
       " u'temperature',\n",
       " u'of',\n",
       " u'10,000',\n",
       " u'degrees',\n",
       " u'Fahrenheit',\n",
       " u'and',\n",
       " u'frequent',\n",
       " u'eruptions',\n",
       " u'of',\n",
       " u'ionized',\n",
       " u'gases',\n",
       " u'flowing',\n",
       " u'along',\n",
       " u'strong',\n",
       " u'magnetic',\n",
       " u'fields',\n",
       " u',',\n",
       " u'the',\n",
       " u'sun',\n",
       " u'is',\n",
       " u'the',\n",
       " u'first',\n",
       " u'star',\n",
       " u'we\\u2019ve',\n",
       " u'seen',\n",
       " u'with',\n",
       " u'the',\n",
       " u'right',\n",
       " u'conditions',\n",
       " u'to',\n",
       " u'support',\n",
       " u'fire',\n",
       " u'organisms',\n",
       " u',',\n",
       " u'and',\n",
       " u'we',\n",
       " u'believe',\n",
       " u'there',\n",
       " u'is',\n",
       " u'evidence',\n",
       " u'to',\n",
       " u'support',\n",
       " u'the',\n",
       " u'theory',\n",
       " u'that',\n",
       " u'fire-bacteria',\n",
       " u',',\n",
       " u'fire-insects',\n",
       " u',',\n",
       " u'and',\n",
       " u'even',\n",
       " u'tiny',\n",
       " u'fire-fish',\n",
       " u'were',\n",
       " u'once',\n",
       " u'perhaps',\n",
       " u'populous',\n",
       " u'on',\n",
       " u'the',\n",
       " u'sun\\u2019s',\n",
       " u'surface.\\u201d',\n",
       " u'Scientists',\n",
       " u'cautioned',\n",
       " u'that',\n",
       " u'despite',\n",
       " u'the',\n",
       " u'exciting',\n",
       " u'possibilities',\n",
       " u'of',\n",
       " u'fire-life',\n",
       " u'on',\n",
       " u'the',\n",
       " u'star',\n",
       " u',',\n",
       " u'there',\n",
       " u'are',\n",
       " u'numerous',\n",
       " u'logistical',\n",
       " u',',\n",
       " u'moral',\n",
       " u',',\n",
       " u'and',\n",
       " u'ethical',\n",
       " u'questions',\n",
       " u'to',\n",
       " u'resolve',\n",
       " u'before',\n",
       " u'scientists',\n",
       " u'could',\n",
       " u'even',\n",
       " u'begin',\n",
       " u'to',\n",
       " u'entertain',\n",
       " u'the',\n",
       " u'possibility',\n",
       " u'of',\n",
       " u'putting',\n",
       " u'fire-people',\n",
       " u'on',\n",
       " u'the',\n",
       " u'sun',\n",
       " u'.',\n",
       " u'\\ufeffWASHINGTON',\n",
       " u'In',\n",
       " u'an',\n",
       " u'announcement']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Assign POS tags to the words in the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "textlist = [x[0] for x in tagged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# filter_for_tags\n",
    "defaulttags = ['NN','JJ','NNP']\n",
    "tagged_filtered = [item for item in tagged if item[1] in defaulttags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'surface', 'NN'),\n",
       " (u'temperature', 'NN'),\n",
       " (u'Fahrenheit', 'NNP'),\n",
       " (u'frequent', 'JJ'),\n",
       " (u'ionized', 'JJ'),\n",
       " (u'strong', 'JJ'),\n",
       " (u'magnetic', 'JJ'),\n",
       " (u'sun', 'NN'),\n",
       " (u'first', 'JJ'),\n",
       " (u'star', 'NN'),\n",
       " (u'we\\u2019ve', 'NN'),\n",
       " (u'right', 'JJ'),\n",
       " (u'fire', 'NN'),\n",
       " (u'evidence', 'NN'),\n",
       " (u'theory', 'NN'),\n",
       " (u'fire-bacteria', 'JJ'),\n",
       " (u'tiny', 'JJ'),\n",
       " (u'fire-fish', 'JJ'),\n",
       " (u'populous', 'JJ'),\n",
       " (u'sun\\u2019s', 'NN'),\n",
       " (u'surface.\\u201d', 'NN'),\n",
       " (u'exciting', 'JJ'),\n",
       " (u'fire-life', 'NN'),\n",
       " (u'star', 'NN'),\n",
       " (u'numerous', 'JJ'),\n",
       " (u'logistical', 'JJ'),\n",
       " (u'moral', 'JJ'),\n",
       " (u'ethical', 'JJ'),\n",
       " (u'possibility', 'NN'),\n",
       " (u'fire-people', 'NN'),\n",
       " (u'sun', 'NN'),\n",
       " (u'\\ufeffWASHINGTON', 'NN'),\n",
       " (u'announcement', 'NN')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*Normalize* - return a list of tuples with the first item's periods removed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tagged_filtered_normalized = [(item[0].replace('.',''), item[1]) for item in tagged_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def unique_everseen(iterable, key=None):\n",
    "    \"\"\" List unique elements in order of appearance.  \n",
    "   \n",
    "    Examples:\n",
    "    unique_everseen('AAAABBBCCDAABBB') --> A B C D  \n",
    "    unique_everseen('ABBCcAD', str.lower) --> A B C D \n",
    "    \"\"\"  \n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    if key is None:\n",
    "        for element in [x for x in iterable if x not in seen]:\n",
    "            seen_add(element)\n",
    "            yield element\n",
    "    else:\n",
    "        for element in iterable:\n",
    "            k = key(element)\n",
    "            if k not in seen:\n",
    "                seen_add(k)\n",
    "                yield element\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "unique_word_set=unique_everseen([x[0] for x in tagged_filtered_normalized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_set_list = list(unique_word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'surface',\n",
       " u'temperature',\n",
       " u'Fahrenheit',\n",
       " u'frequent',\n",
       " u'ionized',\n",
       " u'strong',\n",
       " u'magnetic',\n",
       " u'sun',\n",
       " u'first',\n",
       " u'star',\n",
       " u'we\\u2019ve',\n",
       " u'right',\n",
       " u'fire',\n",
       " u'evidence',\n",
       " u'theory',\n",
       " u'fire-bacteria',\n",
       " u'tiny',\n",
       " u'fire-fish',\n",
       " u'populous',\n",
       " u'sun\\u2019s',\n",
       " u'surface\\u201d',\n",
       " u'exciting',\n",
       " u'fire-life',\n",
       " u'star',\n",
       " u'numerous',\n",
       " u'logistical',\n",
       " u'moral',\n",
       " u'ethical',\n",
       " u'possibility',\n",
       " u'fire-people',\n",
       " u'sun',\n",
       " u'\\ufeffWASHINGTON',\n",
       " u'announcement']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This will be used to determine adjacent words in order to construct keyphrases with two words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build Graph  \n",
    "\n",
    "Return a networkx graph instance.  \n",
    "\n",
    "Initialize an undirected graph.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gr = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gr.add_nodes_from(word_set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nodePairs = list(itertools.combinations(word_set_list,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Add edges to the graph (weighted by Levenshtein distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def levenshtein_distance(first,second):\n",
    "    \"\"\" Return the levenshtein distance between two strings.  \n",
    "    \n",
    "    http://rosettacode.org/wiki/Levenshtein_distance#Python\n",
    "    \"\"\"\n",
    "    if len(first) > len(second):\n",
    "        first, second = second, first\n",
    "    distances = range(len(first)+1)\n",
    "    for index2, char2 in enumerate(second):\n",
    "        new_distances = [index2 + 1]\n",
    "        for index1, char1 in enumerate(first):\n",
    "            if char1 == char2:\n",
    "                new_distances.append(distances[index1])\n",
    "            else:\n",
    "                new_distances.append(1 + min((distances[index1], \n",
    "                                                distances[index1+1],\n",
    "                                                 new_distances[-1])))\n",
    "        distances = new_distances\n",
    "    return distances[-1]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For example, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'surface', u'temperature')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_pair = nodePairs[0]; example_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein_distance( example_pair[0], example_pair[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, u't'),\n",
       " (1, u'e'),\n",
       " (2, u'm'),\n",
       " (3, u'p'),\n",
       " (4, u'e'),\n",
       " (5, u'r'),\n",
       " (6, u'a'),\n",
       " (7, u't'),\n",
       " (8, u'u'),\n",
       " (9, u'r'),\n",
       " (10, u'e')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[( index2, char2 ) for index2, char2 in enumerate(example_pair[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for pair in nodePairs:\n",
    "    firstString = pair[0]\n",
    "    secondString = pair[1]\n",
    "    levDistance = levenshtein_distance(firstString, secondString)\n",
    "    gr.add_edge(firstString, secondString, weight=levDistance)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## pageRank - \n",
    "\n",
    "initial value of 1.0, error tolerance of 0.0001, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "calculated_page_rank = nx.pagerank(gr, weight='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Most important words in ascending order of importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "keyphrases = sorted(calculated_page_rank, key=calculated_page_rank.get, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The number of keyphrases returned will be relative to the size of the text (a third of the number of vertices).  \n",
    "\n",
    "So my guess is that it's arbitrary or set manually the relative size, in this case 1/3 here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "one_third = len(word_set_list) // 3 \n",
    "keyphrases_third = keyphrases[0:one_third + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take keyphrases with multiple words into consideration as done in the paper - if 2 words are adjacent in the text and are selected as keywords, join them together.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modified_key_phrases = set([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeps track of individual keywords that have been joined to form a keyphrase.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dealt_with = set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "j=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while j < len(textlist):\n",
    "    first  = textlist[i]\n",
    "    second = textlist[j]\n",
    "    if first in keyphrases_third and second in keyphrases_third:\n",
    "        keyphrase = first + ' ' + second\n",
    "        modified_key_phrases.add(keyphrase)\n",
    "        dealt_with.add(first)\n",
    "        dealt_with.add(second)\n",
    "    else:\n",
    "        if first in keyphrases_third and first not in dealt_with:\n",
    "            modified_key_phrases.add(first)\n",
    "            \n",
    "        # if this is the last word in the text, and it is a keyword, it\n",
    "        # definitely has no chance of being a keyphrase at this point\n",
    "        if j == len(textlist) - 1 and second in keyphrases_third and second not in dealt_with:\n",
    "            modified_key_phrases.add(second)\n",
    "        \n",
    "    i = i + 1\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'Fahrenheit',\n",
       " u'announcement',\n",
       " u'exciting',\n",
       " u'fire-bacteria',\n",
       " u'fire-fish',\n",
       " u'fire-people',\n",
       " u'numerous logistical',\n",
       " u'populous',\n",
       " u'possibility',\n",
       " u'temperature',\n",
       " u'\\ufeffWASHINGTON'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_key_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
