{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/topolo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/topolo/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"./10.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fread = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xe2\\x80\\x9cWith a surface temperature of 10,000 degrees Fahrenheit and frequent eruptions of ionized gases flowing along strong magnetic fields, the sun is the first star we\\xe2\\x80\\x99ve seen with the right conditions to support fire organisms, and we believe there is evidence to support the theory that fire-bacteria, fire-insects, and even tiny fire-fish were once perhaps populous on the sun\\xe2\\x80\\x99s surface.\\xe2\\x80\\x9d Scientists cautioned that despite the exciting possibilities of fire-life on the star, there are numerous logistical, moral, and ethical questions to resolve before scientists could even begin to entertain the possibility of putting fire-people on the sun. \\xef\\xbb\\xbfWASHINGTON In an announcement'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fread=fread.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the text using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_tokens = nltk.word_tokenize(fread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign POS tags to the words in the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textlist = [x[0] for x in tagged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter_for_tags\n",
    "defaulttags = ['NN','JJ','NNP']\n",
    "tagged_filtered = [item for item in tagged if item[1] in defaulttags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'surface', 'NN'),\n",
       " (u'temperature', 'NN'),\n",
       " (u'Fahrenheit', 'NNP'),\n",
       " (u'frequent', 'JJ'),\n",
       " (u'ionized', 'JJ'),\n",
       " (u'strong', 'JJ'),\n",
       " (u'magnetic', 'JJ'),\n",
       " (u'sun', 'NN'),\n",
       " (u'first', 'JJ'),\n",
       " (u'star', 'NN'),\n",
       " (u'we\\u2019ve', 'NN'),\n",
       " (u'right', 'JJ'),\n",
       " (u'fire', 'NN'),\n",
       " (u'evidence', 'NN'),\n",
       " (u'theory', 'NN'),\n",
       " (u'fire-bacteria', 'JJ'),\n",
       " (u'tiny', 'JJ'),\n",
       " (u'fire-fish', 'JJ'),\n",
       " (u'populous', 'JJ'),\n",
       " (u'sun\\u2019s', 'NN'),\n",
       " (u'surface.\\u201d', 'NN'),\n",
       " (u'exciting', 'JJ'),\n",
       " (u'fire-life', 'NN'),\n",
       " (u'star', 'NN'),\n",
       " (u'numerous', 'JJ'),\n",
       " (u'logistical', 'JJ'),\n",
       " (u'moral', 'JJ'),\n",
       " (u'ethical', 'JJ'),\n",
       " (u'possibility', 'NN'),\n",
       " (u'fire-people', 'NN'),\n",
       " (u'sun', 'NN'),\n",
       " (u'\\ufeffWASHINGTON', 'NN'),\n",
       " (u'announcement', 'NN')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Normalize* - return a list of tuples with the first item's periods removed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagged_filtered_normalized = [(item[0].replace('.',''), item[1]) for item in tagged_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unique_everseen(iterable, key=None):\n",
    "    \"\"\" List unique elements in order of appearance.  \n",
    "   \n",
    "    Examples:\n",
    "    unique_everseen('AAAABBBCCDAABBB') --> A B C D  \n",
    "    unique_everseen('ABBCcAD', str.lower) --> A B C D \n",
    "    \"\"\"  \n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    if key is None:\n",
    "        for element in [x for x in iterable if x not in seen]:\n",
    "            seen_add(element)\n",
    "            yield element\n",
    "    else:\n",
    "        for element in iterable:\n",
    "            k = key(element)\n",
    "            if k not in seen:\n",
    "                seen_add(k)\n",
    "                yield element\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_word_set=unique_everseen([x[0] for x in tagged_filtered_normalized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_set_list = list(unique_word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'surface',\n",
       " u'temperature',\n",
       " u'Fahrenheit',\n",
       " u'frequent',\n",
       " u'ionized',\n",
       " u'strong',\n",
       " u'magnetic',\n",
       " u'sun',\n",
       " u'first',\n",
       " u'star',\n",
       " u'we\\u2019ve',\n",
       " u'right',\n",
       " u'fire',\n",
       " u'evidence',\n",
       " u'theory',\n",
       " u'fire-bacteria',\n",
       " u'tiny',\n",
       " u'fire-fish',\n",
       " u'populous',\n",
       " u'sun\\u2019s',\n",
       " u'surface\\u201d',\n",
       " u'exciting',\n",
       " u'fire-life',\n",
       " u'star',\n",
       " u'numerous',\n",
       " u'logistical',\n",
       " u'moral',\n",
       " u'ethical',\n",
       " u'possibility',\n",
       " u'fire-people',\n",
       " u'sun',\n",
       " u'\\ufeffWASHINGTON',\n",
       " u'announcement']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be used to determine adjacent words in order to construct keyphrases with two words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph  \n",
    "\n",
    "Return a networkx graph instance.  \n",
    "\n",
    "Initialize an undirected graph.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gr = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gr.add_nodes_from(word_set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodePairs = list(itertools.combinations(word_set_list,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add edges to the graph (weighted by Levenshtein distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levenshtein_distance(first,second):\n",
    "    \"\"\" Return the levenshtein distance between two strings.  \n",
    "    \n",
    "    http://rosettacode.org/wiki/Levenshtein_distance#Python\n",
    "    \"\"\"\n",
    "    if len(first) > len(second):\n",
    "        first, second = second, first\n",
    "    distances = range(len(first)+1)\n",
    "    for index2, char2 in enumerate(second):\n",
    "        new_distances = [index2 + 1]\n",
    "        for index1, char1 in enumerate(first):\n",
    "            if char1 == char2:\n",
    "                new_distances.append(distances[index1])\n",
    "            else:\n",
    "                new_distances.append(1 + min((distances[index1], \n",
    "                                                distances[index1+1],\n",
    "                                                 new_distances[-1])))\n",
    "        distances = new_distances\n",
    "    return distances[-1]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'surface', u'temperature')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_pair = nodePairs[0]; example_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein_distance( example_pair[0], example_pair[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, u't'),\n",
       " (1, u'e'),\n",
       " (2, u'm'),\n",
       " (3, u'p'),\n",
       " (4, u'e'),\n",
       " (5, u'r'),\n",
       " (6, u'a'),\n",
       " (7, u't'),\n",
       " (8, u'u'),\n",
       " (9, u'r'),\n",
       " (10, u'e')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[( index2, char2 ) for index2, char2 in enumerate(example_pair[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pair in nodePairs:\n",
    "    firstString = pair[0]\n",
    "    secondString = pair[1]\n",
    "    levDistance = levenshtein_distance(firstString, secondString)\n",
    "    gr.add_edge(firstString, secondString, weight=levDistance)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pageRank - \n",
    "\n",
    "initial value of 1.0, error tolerance of 0.0001, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculated_page_rank = nx.pagerank(gr, weight='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most important words in ascending order of importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keyphrases = sorted(calculated_page_rank, key=calculated_page_rank.get, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of keyphrases returned will be relative to the size of the text (a third of the number of vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
